# -*- coding: utf-8 -*-
"""Cross-modal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W7ghl22QfUUFot7OPXUnls_HyhTufESN

## Imports
"""

import pickle
from cca_zoo.models import CCA
import copy
import random
from sklearn.preprocessing import normalize
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import seaborn as sns
import json

"""# Load Training Data"""

#Load training data
def load_train_data():
    train_embs = open("embeddings_train1.pkl",'rb')
    x_train = pickle.load(train_embs)

    y_train = []
    instructions = open("instructions_embeddings_train.pkl",'rb')
    y_train.append(pickle.load(instructions))

    ingredients = open("ingredients_embeddings_train.pkl",'rb')
    y_train.append(pickle.load(ingredients))

    titles = open("title_embeddings_train.pkl",'rb')
    y_train.append(pickle.load(titles))
    return x_train, y_train

x_train, y_train = load_train_data()

def load_average_embs_train_data():
    train_embs = open("embeddings_train1.pkl",'rb')
    x_train = pickle.load(train_embs)

    return x_train

avg_emb_train = load_average_embs_train_data()

"""# Load Testing Data"""

#Load testing data
def load_test_data():
    y_test = []
    images_test = open("embeddings_test1.pkl",'rb')
    x_test = pickle.load(images_test)

    instructions_test = open("instructions_embeddings_test.pkl",'rb')
    y_test.append(pickle.load(instructions_test))

    ingredients_test = open("ingredients_embeddings_test.pkl",'rb')
    y_test.append(pickle.load(ingredients_test))

    titles_test = open("title_embeddings_test.pkl",'rb')
    y_test.append(pickle.load(titles_test))
    
    return x_test, y_test

x_test, y_test = load_test_data()

print(x_test[0][0].shape)

def load_average_embs_test_data():
    test_embs = open("embeddings_test1.pkl",'rb')
    x_test = pickle.load(test_embs)

    return x_test

avg_emb_test = load_average_embs_test_data()

"""# CCA"""

def perform_CCA(d, X, Y):
    cca_embed = CCA(latent_dims=d)
    cca_embed.fit((X,Y))
    
    return cca_embed

"""# Dump models"""

#Dump pickle files
def model_dump(filename, modelname):
    with open(filename,"wb") as f:
        pickle.dump(modelname,f)

#CCA for image,text embeddings for different components
def cca_controller(X, Y, model_name):
    d = [10,20,50,100,150,300,500,1000]
    cca_by_comp_list = []
    for i in range(len(d)):
        cca_by_comp_list.append(perform_CCA(d[i], X, Y))
        #cca_by_comp_list.append(perform_CCA(d[i], x[0], y1[0]))
        
        #save model
        model_dump(model_name + str(d[i])+".pkl", cca_by_comp_list[i])

"""# Run CCA for Image, Text embeddings for different components"""

model_names = ['instructions', 'ingredients', 'title']
for i in range(len(y_test)):
    cca_controller(x_test[0], y_test[i][0], model_names[i])

"""##  Run CCA Average embeddings model"""

#train and save models
cca_controller(avg_emb_train[0], avg_emb_train[1], 'avg-emb')

"""# image2Recipe Evaluation"""

def evaluation(emb1, emb2, embedding_type):
    names = copy.deepcopy(x_test[2])

    idxs = np.argsort(names)
    names = names[idxs]
    im_vecs = normalize(emb1)[idxs]
    text_vecs = normalize(emb2)[idxs]

    # Ranker+
    
    N = 1000
    idxs = range(N)

    glob_rank = []
    glob_recall = {1:0.0,5:0.0,10:0.0}
    for i in range(10):

        ids = random.sample(range(0,len(names)), N)
        emb1_sub = im_vecs[ids,:]
        emb2_sub = text_vecs[ids,:]
        ids_sub = names[ids]

        if embedding_type == 'im2recipe':
            sims = np.dot(emb1_sub,emb2_sub.T) # for im2recipe
        elif embedding_type == 'recipe2im':
            sims = np.dot(emb2_sub,emb1_sub.T) # for recipe2im

        med_rank = []
        recall = {1:0.0,5:0.0,10:0.0}

        for ii in idxs:

            name = ids_sub[ii]
            # get a column of similarities
            sim = sims[ii,:]

            # sort indices in descending order
            sorting = np.argsort(sim)[::-1].tolist()

            # find where the index of the pair sample ended up in the sorting
            pos = sorting.index(ii)

            if (pos+1) == 1:
                recall[1]+=1
            if (pos+1) <=5:
                recall[5]+=1
            if (pos+1)<=10:
                recall[10]+=1

            # store the position
            med_rank.append(pos+1)

        for i in recall.keys():
            recall[i]=recall[i]/N

        med = np.median(med_rank)
        print("median", med)

        for i in recall.keys():
            glob_recall[i]+=recall[i]
        glob_rank.append(med)

    for i in glob_recall.keys():
        glob_recall[i] = glob_recall[i]/10
    print("Mean median", np.average(glob_rank))
    print("Recall", glob_recall)
    return np.average(glob_rank), list(glob_recall.values())

#load model
def load_and_evaluate(embedding_type):
    d = [10,20,50,100,150,300,500,1000]
    
    #load average test embedddings
    
    model_names = ['instructions', 'ingredients', 'title']
    #load models by dimension for each kind(title, ingredients, instructions) and evaluate each
    median_rank_by_components = {}
    recall_rate_by_components = {}
    for m in range(len(model_names)):
        print("Model name = ", model_names[m])
        for i in range(len(d)):
            model_filename = "models/" + model_names[m] + str(d[i])+".pkl"
            with open(model_filename,"rb") as f:
                print("Dimensions = ", d[i])
                model = pickle.load(f)
                emb1, emb2 = model.transform([x_test[0], y_test[m][0]])
                median_rank, recall_rate = evaluation(emb1, emb2, embedding_type)
                median_rank_by_components[model_names[m] + str(d[i])] = median_rank
                recall_rate_by_components[model_names[m] + str(d[i])] = recall_rate
    return median_rank_by_components, recall_rate_by_components

def test_model(embdedding_type):
    median_rank_by_components, recall_rate_by_components = load_and_evaluate(embdedding_type)

    #convert to dataframe
    mdR_df = pd.DataFrame(median_rank_by_components.items())
    recall_df = pd.DataFrame(recall_rate_by_components.items())
    print(mdR_df)
    print(recall_df)
    return median_rank_by_components, recall_rate_by_components

medR, recall = test_model('im2recipe')
df1 = pd.DataFrame(medR.items())
df2 = pd.DataFrame(recall.items())

"""## Median Rank Evaluation"""



#3 g
def medianRankPlotter(medR):
    dimensions = np.array([10,20,50,100,150,300,500,1000])
    median_rank_list = list(medR.values())
    print(median_rank_list)
    #what is y?
    #plt.subplot(1, 3, 1) # row 1, col 2 index 1

    titles = ['Instructions', 'Ingredients', 'Title']
    for i in range(3):
        plt.title("Median Rank for Image-"+ titles[i])
        plt.xlabel('Dimensions')
        plt.ylabel('Median Rank')
        plt.plot(dimensions, median_rank_list[i*8:(i*8)+8])

        #plt.subplot(1, 2, 2) # index 2
        #plt.subplots_adjust(left=0.001,
    #                         bottom=0.1, 
    #                         right=1.9, 
    #                         top=0.9, 
    #                         wspace=0.4, 
    #                         hspace=0.4)
        plt.show()
        
        
    #what goes on the x-axis? The value of k? Then where do the dimensions go?
    # When k=1 for all, k=5 for all, k = 10 for all
medianRankPlotter(medR)

#Average test
def evalaute_average(embedding_type):
    d = [10,20,50,100,150,300,500,1000]
    
    #load average test embedddings
    
    avg_median_rank_by_components = {}
    avg_recall_rate_by_components = {}
    
    for i in range(len(d)):
        model_filename = "models/avg-emb" + str(d[i])+".pkl"
        with open(model_filename,"rb") as f:
            print("Dimensions = ", d[i])
            model = pickle.load(f)
            x_score, y_score = model.transform([x_test[0], x_test[1]])
            median_rank, recall_rate = evaluation(x_score, y_score, embedding_type)
            avg_median_rank_by_components['avg-emb' + str(d[i])] = median_rank
            avg_recall_rate_by_components['avg-emb' + str(d[i])] = recall_rate
    return x_score, y_score, avg_median_rank_by_components, avg_recall_rate_by_components

def test_avg_model(embdedding_type):
    x_score, y_score, median_rank_by_components, recall_rate_by_components = evalaute_average(embdedding_type)

    #convert to dataframe
    #avg_mdR_df = pd.DataFrame(median_rank_by_components.items())
    avg_recall_df = pd.DataFrame(recall_rate_by_components.items())

    return x_score, y_score,median_rank_by_components, avg_recall_df

def avg_medianRankPlotter(medR):
    dimensions = np.array([10,20,50,100,150,300,500,1000])
    median_rank_list = list(medR.values())
    #print(median_rank_list)   
    
    plt.title("Avg Median Rank for Image-text")
    plt.xlabel('Dimensions')
    plt.ylabel('Median Rank')
    plt.plot(dimensions, median_rank_list)
    plt.show()

x_score, y_score, im2median_rank_by_components, im2avg_recall_df = test_avg_model('im2recipe')
x_score, y_score, r2Imedian_rank_by_components, r2Iavg_recall_df = test_avg_model('recipe2im')

avg_medianRankPlotter(im2median_rank_by_components)

"""## Recall rate evaluation"""

#what is on the x?
#the dimension values
im2RecipeRecall = zip(df2[1][0],df2[1][1],df2[1][2],df2[1][3],df2[1][4],df2[1][5],df2[1][6],df2[1][7],
             df2[1][8],df2[1][9],df2[1][10],df2[1][11],df2[1][12],df2[1][13],df2[1][14],df2[1][15],
             df2[1][16],df2[1][17],df2[1][18],df2[1][19],df2[1][20],df2[1][21],df2[1][22], df2[1][23], im2avg_recall_df[1][0],im2avg_recall_df[1][1],im2avg_recall_df[1][2],
                           im2avg_recall_df[1][3],im2avg_recall_df[1][4],im2avg_recall_df[1][5],
                           im2avg_recall_df[1][6],im2avg_recall_df[1][7])

#for r in recall_zipped_by_dimensions:
#    print(r)

def recallRatePlotter(embedding_type, recall_zipped):
    #zip for every k
    dimensions = np.array([10,20,50,100,150,300,500,1000])

    #what is y?
    #plt.subplot(1, 3, 1) # row 1, col 2 index 1

    titles = ['Instructions', 'Ingredients', 'Title', 'Average-Text']
    k = [1,5,10]
    plot_num = 0

    for r in recall_zipped:
        plt.figure(figsize=(10,10))

        plt.title(embedding_type + " Recall rate for (k=" + str(k[plot_num]) +')')
        plt.xlabel('Dimensions')
        plt.ylabel('Recall rate')
        
        #1 curve for every K. K = 1,5,10
        
        plt.plot(dimensions, list(r)[0:8])
        plt.plot(dimensions, list(r)[8:16])
        plt.plot(dimensions, list(r)[16:24])
        plt.plot(dimensions, list(r)[24:32])

        plot_num += 1
        plt.legend(['Instructions', 'Ingredients', 'Title', 'Average-Text'])

        plt.show()

recallRatePlotter('Im2Recipe', im2RecipeRecall)

"""## Recipe2Image evaluation"""

recipe2IMmedR, recipe2IMrecall = test_model('recipe2im')

"""## Median rank plots"""

medianRankPlotter(recipe2IMmedR)

avg_medianRankPlotter(r2Imedian_rank_by_components)

"""## Recall rate for Recipe2Img"""

r2Imdf2 = pd.DataFrame(recipe2IMrecall.items())
#r2Imdf2
r2Im_recall = zip(r2Imdf2[1][0],r2Imdf2[1][1],r2Imdf2[1][2],r2Imdf2[1][3],r2Imdf2[1][4],r2Imdf2[1][5],r2Imdf2[1][6],r2Imdf2[1][7],
             r2Imdf2[1][8],r2Imdf2[1][9],r2Imdf2[1][10],r2Imdf2[1][11],r2Imdf2[1][12],r2Imdf2[1][13],r2Imdf2[1][14],r2Imdf2[1][15],
             r2Imdf2[1][16],r2Imdf2[1][17],r2Imdf2[1][18],r2Imdf2[1][19],r2Imdf2[1][20],r2Imdf2[1][21],r2Imdf2[1][22], r2Imdf2[1][23], r2Iavg_recall_df[1][0],r2Iavg_recall_df[1][1],r2Iavg_recall_df[1][2],
                           r2Iavg_recall_df[1][3],r2Iavg_recall_df[1][4],r2Iavg_recall_df[1][5],
                           r2Iavg_recall_df[1][6],r2Iavg_recall_df[1][7])

recallRatePlotter('Recipe2Im',r2Im_recall)

"""Pick any 5 words- 5 different words
Rice, Juice, Vanilla, Corn, Muffin
Find the recipes that contain these 5 words from layer1.json
Find ids of the recipes of step 2
Run CCA on these i.e Get embeddinsgs (output from .transform)
Plot using Tsne
"""

json_data = open('layer1.json')

json_file = json.load(json_data)

"""
## Visualising learned embeddings"""

def get_food_to_id_map():
    #food_list = ['rice', 'juice', 'vanilla', 'corn', 'muffin']
    food_list = ['rice', 'juice', 'muffin']

    counter = 0
    food_to_id = {}

    for recipe in json_file:
        #if counter > 100:
        #    break
        ing_list= recipe["ingredients"]
        for all_ings in ing_list:
            #print(all_ings)
            for f in food_list:
                if f in all_ings['text']:
                    if food_to_id.get(f) is None:
                        food_to_id[f] = []
                    food_to_id[f].append(recipe["id"])
    return food_to_id

food_to_id = get_food_to_id_map()

def get_embs_and_labels():
    img_embs = []
    text_embs = []
    labels = []
    for key in food_to_id:
        print(key)
        ids_of_this_food = food_to_id[key]
        #print(ids_of_this_food[0:10])
        for fId in ids_of_this_food:
            #print(fId)
            #print(x_train[2])
            #get the entry of this id from x_train
            ind = np.where(x_train[2] == fId)
            for indexes in ind:
            #print(ind)
                img_embs.append(x_train[0][ind])
                text_embs.append(x_train[1][ind])
                labels.append(key)
    return img_embs, text_embs, labels

img_embs, text_embs, labels = get_embs_and_labels()

print(len(img_embs))
print(len(text_embs))
print(len(labels))
print(img_embs[0].shape)
print(img_embs[1].shape)
print(img_embs[2].shape)
print(img_embs[3].shape)
print(img_embs[0])
print(text_embs[0])

filtered_img_embs = []
for i in range(len(img_embs)):
    if img_embs[i].shape != (0,1024):
        filtered_img_embs.append(img_embs[i])

filtered_text_embs = []
filtered_labels = []
for i in range(len(text_embs)):
    if text_embs[i].shape != (0,1024):
        filtered_text_embs.append(text_embs[i])
        filtered_labels.append(labels[i])

shaped_filtered_img_embs = []
for f in filtered_img_embs:
    shaped_filtered_img_embs.append(f.squeeze(0))
    
shaped_filtered_text_embs = []
for f in filtered_text_embs:
    shaped_filtered_text_embs.append(f.squeeze(0))

filtered_labels[0:100]

def get_transform_from_avg_model(X, Y):
    model_filename = "models/avg-emb500.pkl"
    with open(model_filename,"rb") as f:
        model = pickle.load(f)
        x_score, y_score = model.transform([X,Y])
    return x_score, y_score

x_score, y_score = get_transform_from_avg_model(shaped_filtered_img_embs, shaped_filtered_text_embs)

def tsne(X):
    print("Running TSNE")
    z = TSNE(n_components=2, learning_rate='auto',
                      init='random').fit_transform(X)

    df_subset = pd.DataFrame()
    df_subset['tsne-2d-one'] = z[:,0]
    df_subset['tsne-2d-two'] = z[:,1]
    df_subset["y"] = filtered_labels
    print("Finished dataframe")
    return z, df_subset

z, df = tsne(x_score)

print(set(filtered_labels))

def plot(df):
    plt.figure(figsize=(16,10))
    print("Plotting")
    sns.scatterplot(
        x="tsne-2d-one", y="tsne-2d-two",
        hue = df.y.tolist(),
        palette=sns.color_palette("hls", 3),
        data=df,
        legend="full",
        alpha=0.3
    )
    
#c= df.y.tolist()
#df.y.unique()
df["y"] = filtered_labels
plot(df)